import fitz  # PyMuPDF
import pytesseract
from pdf2image import convert_from_path
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import OllamaEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter

# ğŸ“‚ PDFì—ì„œ OCRì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ì¶”ì¶œ
def extract_text_with_ocr(pdf_path):
    """OCRì„ ì‚¬ìš©í•˜ì—¬ PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜"""
    text = ""
    images = convert_from_path(pdf_path)
    for img in images:
        text += pytesseract.image_to_string(img, lang="kor+eng")  # í•œê¸€ + ì˜ì–´ OCR
    return text

# ğŸ“‚ ê¸°ì¡´ í…ìŠ¤íŠ¸ ì¶”ì¶œ ë°©ë²• (OCR ì—†ì´)
def extract_text_from_pdf(pdf_path):
    """PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ëŠ” ê¸°ë³¸ í•¨ìˆ˜"""
    text = ""
    with fitz.open(pdf_path) as doc:
        for page in doc:
            text += page.get_text("text")
    return text if text.strip() else extract_text_with_ocr(pdf_path)  # OCR ì ìš©

# ğŸ“‚ ChromaDB ì €ì¥ ê²½ë¡œ
CHROMA_DB_PATH = "C:/rag-project/chroma_db"

# ğŸ§  Ollama ì„ë² ë”© ëª¨ë¸
embeddings = OllamaEmbeddings(model="mxbai-embed-large")

def process_pdf(pdf_path):
    """PDFë¥¼ ë¶„ì„í•˜ê³  ë²¡í„° DBì— ì €ì¥í•˜ëŠ” í•¨ìˆ˜"""
    extracted_text = extract_text_from_pdf(pdf_path)
    
    if not extracted_text.strip():
        print("âŒ PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    texts = text_splitter.split_text(extracted_text)

    # ë²¡í„° DBì— ì €ì¥
    vectorstore = Chroma.from_texts(texts, embeddings, persist_directory=CHROMA_DB_PATH)
    print("âœ… PDF ë¬¸ì„œê°€ ë²¡í„° DBì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")