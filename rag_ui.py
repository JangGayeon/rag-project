import gradio as gr
from pdf_processor import process_pdf
from langchain.chains import RetrievalQA
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import OllamaEmbeddings
from langchain_community.llms import Ollama

# ChromaDB ì €ì¥ ê²½ë¡œ
CHROMA_DB_PATH = "C:/rag-project/chroma_db"

# Ollama ì„ë² ë”© & ëª¨ë¸ ì„¤ì •
embeddings = OllamaEmbeddings(model="mxbai-embed-large")
vectorstore = Chroma(persist_directory=CHROMA_DB_PATH, embedding_function=embeddings)
retriever = vectorstore.as_retriever()

# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì¶”ê°€
def create_prompt(question, relevant_docs):
    # ë¬¸ì„œ ë‚´ìš©ë“¤ì„ í•˜ë‚˜ë¡œ í•©ì³ì„œ contextë¡œ ì‚¬ìš©
    context = " ".join([doc.page_content for doc in relevant_docs])
    
    # í”„ë¡¬í”„íŠ¸ë¥¼ í•œê¸€ë¡œ ì‘ë‹µí•˜ë„ë¡ ê°•ë ¥íˆ ìœ ë„
    return f"""
    ì•„ë˜ì˜ ë¬¸ì„œ ë‚´ìš©ì— ëŒ€í•œ ì§ˆë¬¸ì„ í•œê¸€ë¡œ ì •í™•í•˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ ë‹µë³€í•´ ì£¼ì„¸ìš”:
    
    ë¬¸ì„œ ë‚´ìš©: {context}
    
    ì§ˆë¬¸: {question}
    
    ë‹µë³€ì€ ë°˜ë“œì‹œ í•œê¸€ë¡œ ì‘ì„±í•´ì•¼ í•˜ë©°, ì œê³µëœ ë¬¸ì„œ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ êµ¬ì²´ì ì´ê³  ì •í™•í•œ ë‹µì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
    """

qa_chain = RetrievalQA.from_chain_type(
    llm=Ollama(model="gemma2"),  # ì—¬ê¸°ì„œ ëª¨ë¸ì„ gemma2-9bë¡œ ë³€ê²½
    chain_type="stuff",
    retriever=retriever
)

# ğŸ“‚ **PDF ì—…ë¡œë“œ ë° ë¶„ì„ í•¨ìˆ˜**
def handle_upload(pdf_file):
    if pdf_file is None:
        return "âŒ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."
    
    process_pdf(pdf_file.name)  # PDF ì²˜ë¦¬ ì‹¤í–‰
    return "âœ… PDF ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!"

# ğŸ“ **Q&A ì‹œìŠ¤í…œ (ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€)**
def ask_question(question):
    if not question.strip():
        return "âŒ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”!"
    
    # ë¬¸ì„œì—ì„œ ê´€ë ¨ëœ ë‚´ìš©ì„ ê²€ìƒ‰
    retrieved_docs = retriever.get_relevant_documents(question)
    
    if not retrieved_docs:
        return "âŒ ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    # í•œêµ­ì–´ë¡œ ë‹µë³€ì„ ìš”ì²­í•˜ëŠ” í”„ë¡¬í”„íŠ¸ ìƒì„±
    prompt = create_prompt(question, retrieved_docs)
    
    # `qa_chain` ì‹¤í–‰, í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì‚¬ìš©í•˜ì—¬ í•œêµ­ì–´ ë‹µë³€ ìœ ë„
    answer = qa_chain.run(prompt)
    return f"ğŸ“ ë‹µë³€: {answer}"

# ğŸ¨ **Gradio UI ë””ìì¸**
with gr.Blocks() as demo:
    gr.Markdown("ğŸ“„ **PDF ê¸°ë°˜ LLaMA3 RAG Q&A ì‹œìŠ¤í…œ**")

    with gr.Row():
        with gr.Column():
            gr.Markdown("ğŸ“‚ **PDF íŒŒì¼ ì—…ë¡œë“œ**")
            upload_button = gr.File(label="Upload PDF")
            analyze_button = gr.Button("ğŸ“‚ PDF ë¶„ì„")
            output_text = gr.Textbox(label="ì²˜ë¦¬ ìƒíƒœ", interactive=False)
            
            analyze_button.click(fn=handle_upload, inputs=[upload_button], outputs=[output_text])

        with gr.Column():
            gr.Markdown("ğŸ¤– **ì§ˆë¬¸ ì…ë ¥ & ë‹µë³€ ì¶œë ¥**")
            question_input = gr.Textbox(label="Enter your question")
            submit_button = gr.Button("Submit")
            answer_output = gr.Textbox(label="Answer", interactive=False)
            
            submit_button.click(fn=ask_question, inputs=[question_input], outputs=[answer_output])

demo.launch()
