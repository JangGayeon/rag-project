import os
import gradio as gr
from pdf_processor import process_pdf
from langchain.chains import RetrievalQA
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import OllamaEmbeddings
from langchain_community.llms import Ollama

# íŒŒì¼ ì €ì¥ ê²½ë¡œ
UPLOAD_DIR = 'C:/rag-project/pdf-files/'
CHROMA_DB_PATH = "C:/rag-project/chroma_db"

# Ollama ì„ë² ë”© & ëª¨ë¸ ì„¤ì •
embeddings = OllamaEmbeddings(model="mxbai-embed-large")  # ì„ë² ë”© ëª¨ë¸
vectorstore = Chroma(persist_directory=CHROMA_DB_PATH, embedding_function=embeddings)
retriever = vectorstore.as_retriever()  # ë²¡í„° DBì—ì„œ ê²€ìƒ‰ì„ ìœ„í•œ retriever

# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì¶”ê°€
def create_prompt(question, relevant_docs):
    # ë¬¸ì„œ ë‚´ìš©ë“¤ì„ í•˜ë‚˜ë¡œ í•©ì³ì„œ contextë¡œ ì‚¬ìš©
    context = " ".join([doc.page_content for doc in relevant_docs])
    
    # í”„ë¡¬í”„íŠ¸ë¥¼ í•œê¸€ë¡œ ì‘ë‹µí•˜ë„ë¡ ê°•ë ¥íˆ ìœ ë„
    return f"""
    ì•„ë˜ì˜ ë¬¸ì„œ ë‚´ìš©ì— ëŒ€í•œ ì§ˆë¬¸ì„ í•œê¸€ë¡œ ì •í™•í•˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ ë‹µë³€í•´ ì£¼ì„¸ìš”:
    
    ë¬¸ì„œ ë‚´ìš©: {context}
    
    ì§ˆë¬¸: {question}
    
    ë‹µë³€ì€ ë°˜ë“œì‹œ í•œê¸€ë¡œ ì‘ì„±í•´ì•¼ í•˜ë©°, ì œê³µëœ ë¬¸ì„œ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ êµ¬ì²´ì ì´ê³  ì •í™•í•œ ë‹µì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
    """

qa_chain = RetrievalQA.from_chain_type(
    llm=Ollama(model="gemma2"),  # gemma2-9b ëª¨ë¸ ì‚¬ìš©
    chain_type="stuff",
    retriever=retriever
)

# ğŸ“‚ **PDF ì—…ë¡œë“œ ë° ë¶„ì„ í•¨ìˆ˜**
def handle_upload(file, file_type):
    if file is None:
        return "âŒ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."
    
    if file_type == 'pdf':
        process_pdf(file.name)  # PDF ì²˜ë¦¬ ì‹¤í–‰
    elif file_type == 'csv':
        process_csv(file.name)
    elif file_type == 'json':
        process_json(file.name)
    
    # ì—…ë¡œë“œëœ PDF ëª©ë¡ ì—…ë°ì´íŠ¸
    uploaded_pdfs = os.listdir(UPLOAD_DIR)
    return uploaded_pdfs

# CSV íŒŒì¼ ì²˜ë¦¬ í•¨ìˆ˜
def process_csv(file_path):
    import pandas as pd
    df = pd.read_csv(file_path)
    return df.to_dict(orient="records")

# JSON íŒŒì¼ ì²˜ë¦¬ í•¨ìˆ˜
def process_json(file_path):
    import json
    with open(file_path, 'r') as f:
        data = json.load(f)
    return data

# PDF íŒŒì¼ ì‚­ì œ ê¸°ëŠ¥
def delete_pdf(pdf_filename):
    pdf_path = os.path.join(UPLOAD_DIR, pdf_filename)
    if os.path.exists(pdf_path):
        os.remove(pdf_path)
        uploaded_pdfs = os.listdir(UPLOAD_DIR)  # PDF ëª©ë¡ì„ ì—…ë°ì´íŠ¸
        return f"âœ… PDF íŒŒì¼ '{pdf_filename}'ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤!", uploaded_pdfs
    else:
        return f"âŒ íŒŒì¼ '{pdf_filename}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", uploaded_pdfs

# ğŸ“ **Q&A ì‹œìŠ¤í…œ (ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€)**
def ask_question(question, chat_history, chat_name):
    if not question.strip():
        return "âŒ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”!", chat_history

    # ë¬¸ì„œì—ì„œ ê´€ë ¨ëœ ë‚´ìš©ì„ ê²€ìƒ‰
    retrieved_docs = retriever.get_relevant_documents(question)
    
    if not retrieved_docs:
        return "âŒ ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", chat_history

    # í•œêµ­ì–´ë¡œ ë‹µë³€ì„ ìš”ì²­í•˜ëŠ” í”„ë¡¬í”„íŠ¸ ìƒì„±
    prompt = create_prompt(question, retrieved_docs)
    
    # `qa_chain` ì‹¤í–‰, í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì‚¬ìš©í•˜ì—¬ í•œêµ­ì–´ ë‹µë³€ ìœ ë„
    answer = qa_chain.run(prompt)
    
    # ëŒ€í™” ê¸°ë¡ì— ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ Botì˜ ë‹µë³€ë§Œ ê°„ê²°í•˜ê²Œ ì €ì¥
    chat_history.append((question, answer))

    return "", chat_history  # ëŒ€í™” ê¸°ë¡ ì—…ë°ì´íŠ¸ í›„ ì¶œë ¥ ê°’ ë¦¬í„´

# ğŸ¨ **Gradio UI ë””ìì¸**
with gr.Blocks() as demo:
    gr.Markdown("**LLM-RAG ê¸°ë°˜ ë†ì—…ìš© ì–¸ì–´ëª¨ë¸ ì ìš© ì±—ë´‡ ì‹œìŠ¤í…œ**")

    with gr.Row():
        with gr.Column(scale=1, min_width=200):
            # ë„¤ë¹„ê²Œì´ì…˜ ê´€ë ¨ UI
            gr.Markdown("**ë¬¸ì„œ**")
            file_input = gr.File(label="Upload File")
            file_type_dropdown = gr.Dropdown(choices=["pdf", "csv", "json"], label="íŒŒì¼ ìœ í˜• ì„ íƒ")
            upload_button = gr.Button("ì—…ë¡œë“œ")
            output_text = gr.Textbox(label="ì²˜ë¦¬ ìƒíƒœ", interactive=False)
            
            upload_button.click(fn=handle_upload, inputs=[file_input, file_type_dropdown], outputs=[output_text])

            # PDF ëª©ë¡ê³¼ ì‚­ì œ ê¸°ëŠ¥
            gr.Markdown("ğŸ—‚ **ì—…ë¡œë“œëœ PDF ëª©ë¡**")
            pdf_list = gr.Dropdown(choices=os.listdir(UPLOAD_DIR), label="Uploaded PDFs")
            delete_button = gr.Button("ì‚­ì œ")
            delete_output = gr.Textbox(label="ì‚­ì œ ìƒíƒœ", interactive=False)
            
            delete_button.click(fn=delete_pdf, inputs=[pdf_list], outputs=[delete_output, pdf_list])

        with gr.Column(scale=3):
            # ì±„íŒ… ì´ë¦„ ì…ë ¥ë€
            gr.Markdown("ğŸ—¨ **ì±„íŒ… ì´ë¦„**")
            chat_name_input = gr.Textbox(label="ì±„íŒ… ì´ë¦„ ì…ë ¥", placeholder="ì±„íŒ… ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”", interactive=True)

            # ëŒ€í™” ë‚´ì—­ì„ ë³´ì—¬ì£¼ëŠ” Textbox (ë©”ì‹ ì €ì²˜ëŸ¼ ëŒ€í™”ê°€ ìŒ“ì´ëŠ” ì˜ì—­)
            chat_output = gr.Chatbot(label="ëŒ€í™” ë‚´ì—­", height=600)

            # í•˜ë‹¨ì— ì‚¬ìš©ìê°€ ì§ˆë¬¸ì„ ì…ë ¥í•˜ê³ , ì „ì†¡í•˜ëŠ” ë¶€ë¶„
            with gr.Row():
                with gr.Column(scale=0.75):
                    user_input = gr.Textbox(label="ì§ˆë¬¸ ì…ë ¥", placeholder="ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”", interactive=True)
                with gr.Column(scale=0.25):
                    submit_btn = gr.Button("ì „ì†¡")

            # submit ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ì§ˆë¬¸ì„ ì²˜ë¦¬í•˜ê³  ë‹µë³€ì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ ì—°ê²°
            submit_btn.click(fn=ask_question, inputs=[user_input, chat_output, chat_name_input], outputs=[user_input, chat_output])

demo.launch()
